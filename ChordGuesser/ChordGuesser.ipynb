{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T20:31:51.025731900Z",
     "start_time": "2024-04-19T20:31:51.006733200Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.feature\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def plot_song(data):\n",
    "    plt.plot(data)\n",
    "    plt.xlim([0, len(data)])\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T20:31:51.322314400Z",
     "start_time": "2024-04-19T20:31:51.306733Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def import_song(path_to_song):\n",
    "    data, samplerate = librosa.load(path_to_song)\n",
    "    return data, samplerate\n",
    "\n",
    "def show_song(path_to_song):\n",
    "    data, samplerate = import_song(path_to_song)\n",
    "    plot_song(data)\n",
    "\n",
    "def get_song_tempo(path_to_song):\n",
    "    data, samplerate = import_song(path_to_song)\n",
    "    song_onset = librosa.onset.onset_strength(y=data, sr=samplerate)\n",
    "    tempo = librosa.feature.tempo(onset_envelope=song_onset, sr=samplerate)\n",
    "    return tempo\n",
    "\n",
    "def get_song_pitches(path_to_song):\n",
    "    data, samplerate = import_song(path_to_song)\n",
    "    pitches, magnitudes = librosa.piptrack(y=data, sr=samplerate)\n",
    "    return pitches, magnitudes\n",
    "\n",
    "def get_max_pitches(pitches, magnitudes, number_of_notes, time=30):\n",
    "    initial_chord = magnitudes[:, time]\n",
    "    max_index = np.argpartition(initial_chord, -number_of_notes)[-number_of_notes:]\n",
    "    max_pitches = pitches[max_index, time]\n",
    "    return np.sort(max_pitches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T20:31:54.966650900Z",
     "start_time": "2024-04-19T20:31:54.941726800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# Can get away with 3 for Triads, but I made this number is higher\n",
    "# in case I want to expand to predict 7th, 9ths, and more complex chords\n",
    "NOTE_COUNT = 5\n",
    "\n",
    "'''\n",
    "Data source: https://zenodo.org/records/5217057\n",
    "\n",
    "File data has the naming convention:\n",
    "- 3 octaves (3, 4, 5).\n",
    "- 12 base notes per octave: Cn, Df, Dn, Ef, En, Fn, Gf, Gn, Af, An, Bf, Bn. (n is natural, f is flat).\n",
    "- 4 triad types per note: major (j), minor (n), diminished (d), augmented (a). No inversions.\n",
    "- 3 volumes per triad: forte (f), metsoforte (m), piano (p).\n",
    "- Metadata is in the name of the chord. For example: \"piano_4_Af_d_m_45.wav\" is a piano chord, (4) 4th octave,\n",
    "(Af) A flat base note, (d) diminished, (m) metsoforte, 45th example.\n",
    "'''\n",
    "\n",
    "MAJOR_FILE_NAME_SHORTHAND = \"_j_\"\n",
    "MINOR_FILE_NAME_SHORTHAND = \"_n_\"\n",
    "\n",
    "PATH_TO_AUDIO_DATA = \"C://Users//Arthur//Desktop//audio_augmented_x10\"\n",
    "\n",
    "def initialize_model():\n",
    "    training_labels, training_pitches, validation_labels, validation_pitches = split_training_validation_data()\n",
    "\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=4)\n",
    "    model.fit(training_pitches, training_labels)\n",
    "    validate_model(model, validation_labels, validation_pitches)\n",
    "    return model\n",
    "\n",
    "def validate_model(model, validation_labels, validation_pitches):\n",
    "    predictions = model.predict(validation_pitches)\n",
    "    print(f\"accuracy is {accuracy_score(validation_labels, predictions)}\")\n",
    "    print(f\"F1 is {f1_score(validation_labels, predictions, average='micro')}\")\n",
    "\n",
    "def split_training_validation_data():\n",
    "    training_labels, training_pitches, validation_labels, validation_pitches = [], [], [], []\n",
    "\n",
    "    for file in os.listdir(PATH_TO_AUDIO_DATA):\n",
    "        # Focus on major/minor for now - soon will remove this and train on entire dataset (diminished, augmented)\n",
    "        if chord_is_major_or_minor(file):\n",
    "            if file_is_training(file):\n",
    "                append_data(training_labels, training_pitches, file)\n",
    "            else:\n",
    "                append_data(validation_labels, validation_pitches, file)\n",
    "\n",
    "    return training_labels, training_pitches, validation_labels, validation_pitches\n",
    "\n",
    "def chord_is_major_or_minor(file_name):\n",
    "    return MAJOR_FILE_NAME_SHORTHAND or MINOR_FILE_NAME_SHORTHAND in file_name\n",
    "\n",
    "# Want to save some data for verification.\n",
    "# 100 samples per chord type, so we train on the first 80 and save the last 20 for validation.\n",
    "def get_file_number(file_name):\n",
    "    return int(file_name[-6:-4])\n",
    "\n",
    "def file_is_training(file_name):\n",
    "    return get_file_number(file_name) <= 80\n",
    "\n",
    "def append_data(labels, pitches_data, file):\n",
    "    chord = get_chord_name(file)\n",
    "    pitches, magnitudes = get_song_pitches(f\"{PATH_TO_AUDIO_DATA}//{file}\")\n",
    "    max_pitches = get_max_pitches(pitches, magnitudes, NOTE_COUNT)\n",
    "    pitches_data.append(max_pitches)\n",
    "    labels.append(chord)\n",
    "\n",
    "def get_chord_name(file_name):\n",
    "    chord_root = file_name[8:10]\n",
    "    chord_type = assign_chord_type(file_name)\n",
    "    chord_name = f\"{chord_root} {chord_type}\"\n",
    "    return chord_name\n",
    "\n",
    "def assign_chord_type(file_name):\n",
    "    if MAJOR_FILE_NAME_SHORTHAND in file_name:\n",
    "        chord_type = \"Major\"\n",
    "    else:\n",
    "        chord_type = \"Minor\"\n",
    "    return chord_type"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T20:51:18.334712300Z",
     "start_time": "2024-04-19T20:51:18.329713500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9919590643274854\n",
      "F1 is 0.9919590643274854\n"
     ]
    }
   ],
   "source": [
    "trained_model = initialize_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:04:42.717351100Z",
     "start_time": "2024-04-19T20:51:20.191714400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An Minor', 'Fn Minor', 'Ef Major', 'An Major', 'Df Minor', 'Af Minor', 'Af Minor', 'Gf Minor', 'En Minor', 'Fn Minor', 'Gn Minor', 'Ef Minor', 'Cn Minor', 'En Minor', 'Ef Minor', 'Cn Major', 'Gf Minor', 'En Major', 'Fn Minor', 'Cn Minor', 'Gn Minor', 'Gf Minor', 'Gf Minor', 'Cn Minor', 'Af Minor', 'Df Major', 'Af Major', 'Cn Major', 'Dn Minor', 'Df Major', 'Gf Minor', 'En Major', 'An Major', 'An Major', 'An Minor', 'Bf Minor', 'Ef Major', 'Gn Minor', 'Df Minor', 'Dn Major', 'Cn Minor']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def get_prediction(pitches, magnitudes, time_stamp):\n",
    "    max_pitches = get_max_pitches(pitches, magnitudes, NOTE_COUNT, time_stamp)\n",
    "    chord_prediction = trained_model.predict([max_pitches])\n",
    "    return chord_prediction[0]\n",
    "\n",
    "def test_song(song_path):\n",
    "    pitches, magnitudes = get_song_pitches(song_path)\n",
    "    song_length = len(pitches[0])\n",
    "\n",
    "    song_tempo = get_song_tempo(song_path)\n",
    "    song_tempo_int = int(math.floor(song_tempo))\n",
    "\n",
    "    predictions = []\n",
    "    for time_stamp in range(0, song_length, song_tempo_int):\n",
    "        predictions.append(get_prediction(pitches, magnitudes, time_stamp))\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "test_song(\"Songs/Heartaches By The Number In Ab.wav\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:14:43.299012200Z",
     "start_time": "2024-04-19T22:14:41.951012300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
